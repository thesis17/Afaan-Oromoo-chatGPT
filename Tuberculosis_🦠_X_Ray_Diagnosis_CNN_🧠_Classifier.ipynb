{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2332307,
          "sourceType": "datasetVersion",
          "datasetId": 891819
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Tuberculosis ðŸ¦  X-Ray Diagnosis CNN ðŸ§  Classifier",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesis17/Afaan-Oromoo-chatGPT/blob/main/Tuberculosis_%F0%9F%A6%A0_X_Ray_Diagnosis_CNN_%F0%9F%A7%A0_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "tawsifurrahman_tuberculosis_tb_chest_xray_dataset_path = kagglehub.dataset_download('tawsifurrahman/tuberculosis-tb-chest-xray-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "yrE4FFONnwyr"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background ðŸ¤¢\n",
        "Tuberculosis, or TB, is a highly contagious disease caused by the bacteria 'Mycobacterium tuberculosis'. A deadly disease that affects the lungs and spreads to every other organ in the body, it can be spread through the air when someone speaks, coughs, or sneezes, and results in severe coughing, fever, pain, weight loss, night sweats, coughing up blood, and potentially death when left untreated.\n",
        "\n",
        "As someone who knows people who have died from TB, I have created a convolutional neural network to accurately diagnose patients using chest X-rays, with user [Tawsifur Rahman](https://www.kaggle.com/tawsifurrahman)'s \"Tuberculosis (TB) Chest X-ray Database\" dataset, in an attempt to potentially save lives by preventing patients with TB from going untreated and gaining the symptoms mentioned above.\n",
        "\n",
        "This dataset contains 3500 samples of chest X-rays of patients without tuberculosis, and 700 of patients with tuberculosis, that all look similar to the image below, which I will be using to train this CNN.\n",
        "\n",
        "![](https://storage.googleapis.com/kagglesdsdata/datasets/891819/2332307/TB_Chest_Radiography_Database/Normal/Normal-1019.png?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20240713%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240713T160233Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=81e3c3b9b9fa4dfc6654ee819f45aa2a24fd64e87130250359a86f23723efcc10185744e2eb48faf4f82833472a62c4bb2488ed8452ad9bc8ae1e35d46b12e35e845e4ee5be597e3d326fae4b3a5b9e6c0afa958c0d405ae07f03ee0ed70b144d9f2859a8f37529cf2190f5d79df12587c1ad049075555cce2e0561289cacb6c4a9f1a20905092913a2879c439119184186d2f0dc115dd057413f36ec40fbdedaafdac108c0cc62ec31102803194787ac4897ba10359e3422f919932ff72e9e68a936b2c85add5b102f2490b7c4fb1991a4b2957943a0ac2e761c32ce32fef9c0eba91399b394fa799c73017847b9205231fa9f083875579a6da2cd890c31355)"
      ],
      "metadata": {
        "id": "TmAOa6ixnwyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Processing ðŸ–¼ï¸\n",
        "The main problem with the data I wanted to fix was the class imbalance (3500 Normal images vs. 700 TB images).\n",
        "In the code below I first read all the image files with OpenCV in and transformed them into a format suitable for SMOTE upsampling to even out the class counts."
      ],
      "metadata": {
        "id": "wN9khM3Inwys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary libraries:\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:06:18.189203Z",
          "iopub.execute_input": "2024-07-14T21:06:18.189955Z",
          "iopub.status.idle": "2024-07-14T21:06:20.663412Z",
          "shell.execute_reply.started": "2024-07-14T21:06:18.189892Z",
          "shell.execute_reply": "2024-07-14T21:06:20.661642Z"
        },
        "trusted": true,
        "id": "hUVG-BTjnwys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing the values needed for all the image files\n",
        "normaldir = '/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal'\n",
        "tbdir = '/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis'\n",
        "images = []\n",
        "labels = []\n",
        "imagesize = 256"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:06:35.347807Z",
          "iopub.execute_input": "2024-07-14T21:06:35.348269Z",
          "iopub.status.idle": "2024-07-14T21:06:35.354943Z",
          "shell.execute_reply.started": "2024-07-14T21:06:35.348237Z",
          "shell.execute_reply": "2024-07-14T21:06:35.353269Z"
        },
        "trusted": true,
        "id": "k1bHWc8knwyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing all the image directories in the 'images' array and corresponding them to either 1 for TB images or 0 for normal images.\n",
        "for x in os.listdir(normaldir):\n",
        "    imagedir = os.path.join(normaldir, x)\n",
        "    image = cv.imread(imagedir, cv.IMREAD_GRAYSCALE)\n",
        "    image = cv.resize(image, (imagesize, imagesize))\n",
        "    images.append(image)\n",
        "    labels.append(0)\n",
        "\n",
        "for y in os.listdir(tbdir):\n",
        "    imagedir = os.path.join(tbdir, y)\n",
        "    image = cv.imread(imagedir, cv.IMREAD_GRAYSCALE)\n",
        "    image = cv.resize(image, (imagesize, imagesize))\n",
        "    images.append(image)\n",
        "    labels.append(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:06:38.58077Z",
          "iopub.execute_input": "2024-07-14T21:06:38.581227Z",
          "iopub.status.idle": "2024-07-14T21:07:52.314499Z",
          "shell.execute_reply.started": "2024-07-14T21:06:38.581194Z",
          "shell.execute_reply": "2024-07-14T21:07:52.313329Z"
        },
        "trusted": true,
        "id": "7JCjQ6tknwyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting to NumPy arrays since they have more features than regular lists\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "#Splitting the images and labels into training and testing sets, then normalizing the values within them for computational efficiency (from 0-255 scale to 0-1 scale)\n",
        "imagetrain, imagetest, labeltrain, labeltest = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "imagetrain = (imagetrain.astype('float32'))/255\n",
        "imagetest = (imagetest.astype('float32'))/255"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:12:13.823608Z",
          "iopub.execute_input": "2024-07-14T21:12:13.82531Z",
          "iopub.status.idle": "2024-07-14T21:12:14.558905Z",
          "shell.execute_reply.started": "2024-07-14T21:12:13.825257Z",
          "shell.execute_reply": "2024-07-14T21:12:14.557507Z"
        },
        "trusted": true,
        "id": "h1HbEPOmnwyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flattening the image array into 2D (making it [2940 images] x [all the pixels of the image in just one 1D array]) to be suitable for SMOTE oversampling\n",
        "imagetrain = imagetrain.reshape(2940, (imagesize*imagesize))\n",
        "\n",
        "#Performing oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "imagetrain, labeltrain = smote.fit_resample(imagetrain, labeltrain)\n",
        "\n",
        "#Unflattening the images now to use them for convolutional neural network (4914 images of 256x256 size, with 1 color channel (grayscale, as compared to RGB with 3 color channels))\n",
        "imagetrain = imagetrain.reshape(-1, imagesize, imagesize, 1)\n",
        "print(imagetrain.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:12:17.998056Z",
          "iopub.execute_input": "2024-07-14T21:12:17.998545Z",
          "iopub.status.idle": "2024-07-14T21:12:22.614669Z",
          "shell.execute_reply.started": "2024-07-14T21:12:17.998508Z",
          "shell.execute_reply": "2024-07-14T21:12:22.61315Z"
        },
        "trusted": true,
        "id": "t0zd9FvZnwyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classes balanced - equal counts of each label\n",
        "print(np.unique(labeltrain, return_counts=True))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:14:11.136304Z",
          "iopub.execute_input": "2024-07-14T21:14:11.136743Z",
          "iopub.status.idle": "2024-07-14T21:14:11.145432Z",
          "shell.execute_reply.started": "2024-07-14T21:14:11.136705Z",
          "shell.execute_reply": "2024-07-14T21:14:11.144192Z"
        },
        "trusted": true,
        "id": "rCVzjhBwnwyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Time ðŸ§ \n",
        "Using Tensorflow's Sequential API for CNN modeling to diagnose all the patients in the testing set with a high accuracy."
      ],
      "metadata": {
        "id": "zpZuPKkknwyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:19:14.848789Z",
          "iopub.execute_input": "2024-07-14T21:19:14.849255Z",
          "iopub.status.idle": "2024-07-14T21:19:21.060447Z",
          "shell.execute_reply.started": "2024-07-14T21:19:14.849221Z",
          "shell.execute_reply": "2024-07-14T21:19:21.059059Z"
        },
        "trusted": true,
        "id": "9JEpvO4knwyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The CNN model has 3 convolutional layers, each followed by pooling to summarize the features found by the layer, starting with 16 and multiplying by 2 each time for computational efficiency, as bits are structured in powers of 2. 3x3 filters and ReLU activation used.\n",
        "cnn = keras.Sequential(\n",
        "    [\n",
        "    #Input layer, same shape as all the images (256x256x1):\n",
        "    keras.Input(shape=(imagesize, imagesize, 1)),\n",
        "\n",
        "    #1st convolutional layer:\n",
        "    Conv2D(16, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    #2nd convolutional layer:\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    #3rd convolutional layer:\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    #Flattening layer for the dense layers:\n",
        "    Flatten(),\n",
        "\n",
        "    #1st dense layer following the convolutional layers:\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    #Dropout layer with heavy dropout rate to avoid overfitting in the large-ish dataset\n",
        "    Dropout(0.5),\n",
        "\n",
        "    #Output layer that squeezes each image to either 0 or 1 with sigmoid activation\n",
        "    Dense(1, activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:23:58.944396Z",
          "iopub.execute_input": "2024-07-14T21:23:58.945395Z",
          "iopub.status.idle": "2024-07-14T21:23:59.09833Z",
          "shell.execute_reply.started": "2024-07-14T21:23:58.945354Z",
          "shell.execute_reply": "2024-07-14T21:23:59.097127Z"
        },
        "trusted": true,
        "id": "8SGwh81tnwyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the model with parameters best suited for the task at hand:\n",
        "cnn.compile(\n",
        "    loss='binary_crossentropy', #Best for binary classification\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001), #Good starting LR for dataset of this size\n",
        "    metrics=['accuracy'], #Looking for accuracy\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:24:54.569434Z",
          "iopub.execute_input": "2024-07-14T21:24:54.569871Z",
          "iopub.status.idle": "2024-07-14T21:24:54.582221Z",
          "shell.execute_reply.started": "2024-07-14T21:24:54.56984Z",
          "shell.execute_reply": "2024-07-14T21:24:54.580846Z"
        },
        "trusted": true,
        "id": "7BcKdT4cnwyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model, with the ReduceLROnPlateau callback added to it to reduce the learning rate to take smaller steps in increasing the accuracy whenever the learning rate plateaus (goes in the wrong direction)\n",
        "#Doing this with patience=1, meaning it will perform this if it even plateaus for one epoch, since only 10 epochs are used\n",
        "#factor=0.1 means that for every time the learning rate is reduced, it is reduced by a factor of 0.1 - it also won't go lower than 0.00001\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=1, min_lr=0.00001, verbose=1)\n",
        "\n",
        "#Fitting the model w/ the callback. ON VS CODE, batch size of 16 makes each epoch take around a minute in this case w/ good accuracy, making the whole training process 10 min, but on Kaggle it should take longer due to less computational resources:\n",
        "cnn.fit(imagetrain, labeltrain, batch_size=16, epochs=10, verbose=2, callbacks = [reduce_lr])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:29:16.546165Z",
          "iopub.execute_input": "2024-07-14T21:29:16.547417Z",
          "iopub.status.idle": "2024-07-14T21:57:04.884356Z",
          "shell.execute_reply.started": "2024-07-14T21:29:16.547369Z",
          "shell.execute_reply": "2024-07-14T21:57:04.883012Z"
        },
        "trusted": true,
        "id": "9dt3RCo3nwyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the data w/ multiple types of metrics\n",
        "print('TESTING DATA:')\n",
        "cnn.evaluate(imagetest, labeltest, batch_size=32, verbose=2)\n",
        "\n",
        "print('ADVANCED TESTING METRICS:')\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "predictions = cnn.predict(imagetest, batch_size=32)\n",
        "predicted_labels = (predictions > 0.5).astype('int32')\n",
        "print(classification_report(labeltest, predicted_labels))\n",
        "print(confusion_matrix(labeltest, predicted_labels))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-14T21:57:37.889707Z",
          "iopub.execute_input": "2024-07-14T21:57:37.8901Z",
          "iopub.status.idle": "2024-07-14T21:58:10.801277Z",
          "shell.execute_reply.started": "2024-07-14T21:57:37.890037Z",
          "shell.execute_reply": "2024-07-14T21:58:10.800004Z"
        },
        "trusted": true,
        "id": "4plFz6dKnwyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very good accuracy and loss values, and great balance of precision between the 0 and 1 classes."
      ],
      "metadata": {
        "id": "yosmneaCnwyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion ðŸ¤“\n",
        "Though there are obviously better models out there for diagnosing TB from x-ray scans, this model can hopefully work as a starting point to show some of you guys how using a CNN for medical purposes works and how it can benefit our society. Hopefully one day, a 100% accurate TB diagnosis model can be made and properly implemented in the healthcare system so that deaths from TB can be avoided altogether.\n",
        "\n",
        "**But overall, thanks for reading this notebook - it means a lot. If you liked it please make sure to leave an upvote, and check out my other work as well!**"
      ],
      "metadata": {
        "id": "nRizbNSOnwyv"
      }
    }
  ]
}