{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 5312008,
          "sourceType": "datasetVersion",
          "datasetId": 3087304
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "LSTM/GRU on Symtoms2Disease dataset",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesis17/Afaan-Oromoo-chatGPT/blob/main/LSTM_GRU_on_Symtoms2Disease_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "niyarrbarman_symptom2disease_path = kagglehub.dataset_download('niyarrbarman/symptom2disease')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "t6K9jMlQYzB7"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-26T09:00:52.193856Z",
          "iopub.execute_input": "2024-04-26T09:00:52.194322Z",
          "iopub.status.idle": "2024-04-26T09:00:52.202591Z",
          "shell.execute_reply.started": "2024-04-26T09:00:52.194293Z",
          "shell.execute_reply": "2024-04-26T09:00:52.20176Z"
        },
        "trusted": true,
        "id": "K8yBcQeJYzB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Necessary Libraries\n",
        "import string\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:00:53.803327Z",
          "iopub.execute_input": "2024-04-26T09:00:53.803663Z",
          "iopub.status.idle": "2024-04-26T09:00:59.402171Z",
          "shell.execute_reply.started": "2024-04-26T09:00:53.803638Z",
          "shell.execute_reply": "2024-04-26T09:00:59.401396Z"
        },
        "trusted": true,
        "id": "SZ73mxY2YzB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:14.982403Z",
          "iopub.execute_input": "2024-04-26T09:01:14.983301Z",
          "iopub.status.idle": "2024-04-26T09:01:15.015654Z",
          "shell.execute_reply.started": "2024-04-26T09:01:14.983266Z",
          "shell.execute_reply": "2024-04-26T09:01:15.014667Z"
        },
        "trusted": true,
        "id": "IToFDsJqYzB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the Dataset"
      ],
      "metadata": {
        "id": "X_P00JLlYzB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"/kaggle/input/symptom2disease/Symptom2Disease.csv\")\n",
        "df.drop(\"Unnamed: 0\",inplace=True,axis=1)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:22.87316Z",
          "iopub.execute_input": "2024-04-26T09:01:22.873898Z",
          "iopub.status.idle": "2024-04-26T09:01:22.914484Z",
          "shell.execute_reply.started": "2024-04-26T09:01:22.873866Z",
          "shell.execute_reply": "2024-04-26T09:01:22.913595Z"
        },
        "trusted": true,
        "id": "953KbaV9YzB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing steps:stopwords removal,datacleaning etc"
      ],
      "metadata": {
        "id": "spWYPbwhYzB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set of English stopwords we will remove from our text data\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:25.68492Z",
          "iopub.execute_input": "2024-04-26T09:01:25.685789Z",
          "iopub.status.idle": "2024-04-26T09:01:25.694051Z",
          "shell.execute_reply.started": "2024-04-26T09:01:25.685755Z",
          "shell.execute_reply": "2024-04-26T09:01:25.693286Z"
        },
        "trusted": true,
        "id": "2eNCArpVYzB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(sent):\n",
        "    #remove punctuations\n",
        "    sent = sent.translate(str.maketrans('','',string.punctuation)).strip()\n",
        "\n",
        "    #remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(sent)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return \" \".join(words).lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:26.48141Z",
          "iopub.execute_input": "2024-04-26T09:01:26.482117Z",
          "iopub.status.idle": "2024-04-26T09:01:26.487466Z",
          "shell.execute_reply.started": "2024-04-26T09:01:26.482076Z",
          "shell.execute_reply": "2024-04-26T09:01:26.486487Z"
        },
        "trusted": true,
        "id": "z8x9m3XkYzB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean text rows in dataframe\n",
        "df[\"text\"] = df[\"text\"].apply(clean_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:27.721184Z",
          "iopub.execute_input": "2024-04-26T09:01:27.721905Z",
          "iopub.status.idle": "2024-04-26T09:01:28.289445Z",
          "shell.execute_reply.started": "2024-04-26T09:01:27.721878Z",
          "shell.execute_reply": "2024-04-26T09:01:28.288627Z"
        },
        "trusted": true,
        "id": "1ae4NkZLYzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of diseases in our dataset\n",
        "diseases = df[\"label\"].unique()\n",
        "\n",
        "# helper dictionaries to convert diseases to index and vice versa\n",
        "idx2dis = {k:v for k,v in enumerate(diseases)}\n",
        "dis2idx = {v:k for k,v in idx2dis.items()}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:42.708583Z",
          "iopub.execute_input": "2024-04-26T09:01:42.709429Z",
          "iopub.status.idle": "2024-04-26T09:01:42.717103Z",
          "shell.execute_reply.started": "2024-04-26T09:01:42.709396Z",
          "shell.execute_reply": "2024-04-26T09:01:42.716083Z"
        },
        "trusted": true,
        "id": "OaO0IwSfYzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert disease name to index (label encoding)\n",
        "df[\"label\"] = df[\"label\"].apply(lambda x: dis2idx[x])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:43.703136Z",
          "iopub.execute_input": "2024-04-26T09:01:43.703507Z",
          "iopub.status.idle": "2024-04-26T09:01:43.709223Z",
          "shell.execute_reply.started": "2024-04-26T09:01:43.703478Z",
          "shell.execute_reply": "2024-04-26T09:01:43.70834Z"
        },
        "trusted": true,
        "id": "c4ecGJGNYzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train,test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:45.419485Z",
          "iopub.execute_input": "2024-04-26T09:01:45.420084Z",
          "iopub.status.idle": "2024-04-26T09:01:45.428608Z",
          "shell.execute_reply.started": "2024-04-26T09:01:45.42005Z",
          "shell.execute_reply": "2024-04-26T09:01:45.427681Z"
        },
        "trusted": true,
        "id": "4A9RmkB6YzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch dataset object use index to return item, so need to reset non-continuoues index of divided dataset\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:51.06708Z",
          "iopub.execute_input": "2024-04-26T09:01:51.06791Z",
          "iopub.status.idle": "2024-04-26T09:01:51.072436Z",
          "shell.execute_reply.started": "2024-04-26T09:01:51.067878Z",
          "shell.execute_reply": "2024-04-26T09:01:51.07146Z"
        },
        "trusted": true,
        "id": "PQ1AnzR4YzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max number of words in symptoms descriptions (cleaned version)\n",
        "max_words = X_train.apply(lambda x:x.split()).apply(len).max()\n",
        "max_words"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:51.792314Z",
          "iopub.execute_input": "2024-04-26T09:01:51.792622Z",
          "iopub.status.idle": "2024-04-26T09:01:51.805484Z",
          "shell.execute_reply.started": "2024-04-26T09:01:51.792598Z",
          "shell.execute_reply": "2024-04-26T09:01:51.804542Z"
        },
        "trusted": true,
        "id": "_ffdAdxGYzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocabulart using torchtext vocab class\n",
        "counter = Counter()\n",
        "for text in X_train:\n",
        "    counter.update(text.split())\n",
        "\n",
        "vocab = torchtext.vocab.vocab(counter,specials=['<unk>', '<pad>'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:52.511752Z",
          "iopub.execute_input": "2024-04-26T09:01:52.512059Z",
          "iopub.status.idle": "2024-04-26T09:01:52.598279Z",
          "shell.execute_reply.started": "2024-04-26T09:01:52.512034Z",
          "shell.execute_reply": "2024-04-26T09:01:52.59728Z"
        },
        "trusted": true,
        "id": "0fn6TslwYzCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set default index as unknown token\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:54.017997Z",
          "iopub.execute_input": "2024-04-26T09:01:54.018781Z",
          "iopub.status.idle": "2024-04-26T09:01:54.023649Z",
          "shell.execute_reply.started": "2024-04-26T09:01:54.018752Z",
          "shell.execute_reply": "2024-04-26T09:01:54.022675Z"
        },
        "trusted": true,
        "id": "cOJ0xHoMYzCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PyTorch dataset`\n",
        "class DiseaseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, symptoms,labels):\n",
        "        self.symptoms = symptoms\n",
        "        self.labels= torch.tensor(labels.to_numpy())\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.symptoms[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Convert the text to a sequence of word indices\n",
        "        text_indices = [vocab[word] for word in text.split()]\n",
        "\n",
        "        # padding for same length sequence\n",
        "        if len(text_indices)<max_words:\n",
        "            text_indices = text_indices + [1]*(max_words - len(text_indices))\n",
        "\n",
        "        return torch.tensor(text_indices), label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:54.235102Z",
          "iopub.execute_input": "2024-04-26T09:01:54.235697Z",
          "iopub.status.idle": "2024-04-26T09:01:54.242307Z",
          "shell.execute_reply.started": "2024-04-26T09:01:54.235671Z",
          "shell.execute_reply": "2024-04-26T09:01:54.241405Z"
        },
        "trusted": true,
        "id": "46bESctTYzCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate dataset objects\n",
        "train_dataset = DiseaseDataset(X_train, y_train)\n",
        "val_dataset = DiseaseDataset(X_test, y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:55.041323Z",
          "iopub.execute_input": "2024-04-26T09:01:55.041893Z",
          "iopub.status.idle": "2024-04-26T09:01:55.072004Z",
          "shell.execute_reply.started": "2024-04-26T09:01:55.041865Z",
          "shell.execute_reply": "2024-04-26T09:01:55.071305Z"
        },
        "trusted": true,
        "id": "1ifuOIviYzCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose batch size, will start from smaller values as we got smaller dataset\n",
        "batch_size = 8\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:55.825102Z",
          "iopub.execute_input": "2024-04-26T09:01:55.825469Z",
          "iopub.status.idle": "2024-04-26T09:01:55.83162Z",
          "shell.execute_reply.started": "2024-04-26T09:01:55.825442Z",
          "shell.execute_reply": "2024-04-26T09:01:55.830564Z"
        },
        "trusted": true,
        "id": "3sHypWKXYzCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model\n",
        "class RNNModel(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim,num_classes,drop_prob,num_layers=1,bidir=False,seq=\"lstm\"):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.seq = seq\n",
        "        self.bidir_f = 2 if bidir else 0\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "        if seq==\"lstm\":\n",
        "            self.rnn = torch.nn.LSTM(embedding_dim, hidden_dim,\n",
        "                                     num_layers=num_layers,\n",
        "                                     batch_first=True,\n",
        "                                     bidirectional=bidir)\n",
        "        else:\n",
        "            self.rnn = torch.nn.GRU(embedding_dim, hidden_dim,\n",
        "                                 num_layers=num_layers,\n",
        "                                 batch_first=True,\n",
        "                                bidirectional=bidir)\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(drop_prob) #dropout layer\n",
        "        self.fc = torch.nn.Linear(hidden_dim*self.bidir_f, num_classes) # fully connected layer\n",
        "\n",
        "    def forward(self, text_indices):\n",
        "        # Embed the text indices\n",
        "        embedded_text = self.embedding(text_indices)\n",
        "#         print(\"EMB SHAPE: \",embedded_text.shape)\n",
        "\n",
        "        # Pass the embedded text through the RNN\n",
        "        rnn_output,hidden_states = self.rnn(embedded_text)\n",
        "        # Take the last output of the RNN\n",
        "        last_rnn_output = rnn_output[:, -1, :]\n",
        "        x = self.dropout(last_rnn_output)\n",
        "        # Pass the last output of the RNN through the fully connected layer\n",
        "        x = self.fc(x)\n",
        "\n",
        "        # Return the final output\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:56.670699Z",
          "iopub.execute_input": "2024-04-26T09:01:56.671055Z",
          "iopub.status.idle": "2024-04-26T09:01:56.681507Z",
          "shell.execute_reply.started": "2024-04-26T09:01:56.671027Z",
          "shell.execute_reply": "2024-04-26T09:01:56.680555Z"
        },
        "trusted": true,
        "id": "l2O-EnzBYzCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    #choose device for training\n",
        "    device = \"cuda\" if torch.cuda.is_available()  else \"cpu\"\n",
        "    model = model.cuda()\n",
        "    model = model.to(device)\n",
        "    print(\"IS CUDA: \",next(model.parameters()).is_cuda)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for data in train_loader:\n",
        "            inputs,labels = data\n",
        "            inputs,labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            acc = (labels == outputs.argmax(dim=-1)).float().mean().item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs,labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                predicted = outputs.argmax(-1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = (labels == outputs.argmax(dim=-1)).float().mean().item()\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {val_loss}, Train Accuracy: {acc:.2f}  Val Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:57.387038Z",
          "iopub.execute_input": "2024-04-26T09:01:57.387898Z",
          "iopub.status.idle": "2024-04-26T09:01:57.3983Z",
          "shell.execute_reply.started": "2024-04-26T09:01:57.387864Z",
          "shell.execute_reply": "2024-04-26T09:01:57.397264Z"
        },
        "trusted": true,
        "id": "6mRfuW1cYzCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_train))\n",
        "vocab_size = len(vocab)\n",
        "emb_dim = 256\n",
        "hidden_dim = 128\n",
        "drop_prob = 0.4"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:58.500013Z",
          "iopub.execute_input": "2024-04-26T09:01:58.50067Z",
          "iopub.status.idle": "2024-04-26T09:01:58.50768Z",
          "shell.execute_reply.started": "2024-04-26T09:01:58.50064Z",
          "shell.execute_reply": "2024-04-26T09:01:58.506875Z"
        },
        "trusted": true,
        "id": "5EVMVJCoYzCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = RNNModel(vocab_size,emb_dim,hidden_dim,num_classes,drop_prob,num_layers=3,bidir=True, seq=\"lstm\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:01:59.743105Z",
          "iopub.execute_input": "2024-04-26T09:01:59.743482Z",
          "iopub.status.idle": "2024-04-26T09:01:59.777874Z",
          "shell.execute_reply.started": "2024-04-26T09:01:59.743454Z",
          "shell.execute_reply": "2024-04-26T09:01:59.77703Z"
        },
        "trusted": true,
        "id": "6BKsYEKiYzCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UuBWmlotYzCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model_lstm,35)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:02:03.790861Z",
          "iopub.execute_input": "2024-04-26T09:02:03.791495Z",
          "iopub.status.idle": "2024-04-26T09:02:28.619074Z",
          "shell.execute_reply.started": "2024-04-26T09:02:03.791464Z",
          "shell.execute_reply": "2024-04-26T09:02:28.618178Z"
        },
        "trusted": true,
        "id": "oUs1DHvlYzCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = RNNModel(vocab_size,emb_dim,hidden_dim,num_classes,drop_prob,num_layers=1,bidir=True,seq=\"gru\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:03:39.102771Z",
          "iopub.execute_input": "2024-04-26T09:03:39.103312Z",
          "iopub.status.idle": "2024-04-26T09:03:39.116441Z",
          "shell.execute_reply.started": "2024-04-26T09:03:39.103283Z",
          "shell.execute_reply": "2024-04-26T09:03:39.115502Z"
        },
        "trusted": true,
        "id": "2ldQvAISYzCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model_gru,20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:03:48.876045Z",
          "iopub.execute_input": "2024-04-26T09:03:48.8768Z",
          "iopub.status.idle": "2024-04-26T09:03:56.24432Z",
          "shell.execute_reply.started": "2024-04-26T09:03:48.876766Z",
          "shell.execute_reply": "2024-04-26T09:03:56.243435Z"
        },
        "trusted": true,
        "id": "450O1LNjYzCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pred(model,text):\n",
        "    text = clean_text(text)\n",
        "    # Convert the text to a sequence of word indices\n",
        "    text_indices = [vocab[word] for word in text.split()]\n",
        "\n",
        "    # padding for same length sequence\n",
        "    if len(text_indices)<max_words:\n",
        "        text_indices = text_indices + [1]*(max_words - len(text_indices))\n",
        "    text_indices = torch.tensor(text_indices).cuda()\n",
        "    pred = model(text_indices.unsqueeze(0))\n",
        "\n",
        "    print(idx2dis[pred.argmax(1).item()])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:04:00.782306Z",
          "iopub.execute_input": "2024-04-26T09:04:00.782652Z",
          "iopub.status.idle": "2024-04-26T09:04:00.788743Z",
          "shell.execute_reply.started": "2024-04-26T09:04:00.782624Z",
          "shell.execute_reply": "2024-04-26T09:04:00.787803Z"
        },
        "trusted": true,
        "id": "SiwNg1JfYzCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symp2 = \"I've been itching a lot, and it's been accompanied with a rash that looks to be getting worse over time. \\\n",
        "There are also some patches of skin that are different colours from the rest of the skin,\\\n",
        "as well as some lumps that resemble little nodes.\"\n",
        "\n",
        "make_pred(model_lstm, symp2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T09:04:32.072556Z",
          "iopub.execute_input": "2024-04-26T09:04:32.072918Z",
          "iopub.status.idle": "2024-04-26T09:04:32.099587Z",
          "shell.execute_reply.started": "2024-04-26T09:04:32.072887Z",
          "shell.execute_reply": "2024-04-26T09:04:32.098631Z"
        },
        "trusted": true,
        "id": "oBVdhAdZYzCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cU1_1Eu5YzCC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}