{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9982049,
          "sourceType": "datasetVersion",
          "datasetId": 6142445
        },
        {
          "sourceId": 10660773,
          "sourceType": "datasetVersion",
          "datasetId": 6601262
        },
        {
          "sourceId": 104449,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 68809,
          "modelId": 91102
        }
      ],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "testing",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesis17/Afaan-Oromoo-chatGPT/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "artemminiailo_medicalconversations2disease_path = kagglehub.dataset_download('artemminiailo/medicalconversations2disease')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "TaCvz7DpOPQp"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers bitsandbytes peft > /dev/null"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:51:41.154095Z",
          "iopub.execute_input": "2025-02-04T12:51:41.15443Z",
          "iopub.status.idle": "2025-02-04T12:51:48.075856Z",
          "shell.execute_reply.started": "2025-02-04T12:51:41.154403Z",
          "shell.execute_reply": "2025-02-04T12:51:48.07463Z"
        },
        "id": "Ij-RVLVTOPQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import Dataset, load_dataset, DatasetDict\n",
        "from peft import LoraConfig, get_peft_model, PeftConfig\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainingArguments,\n",
        "                          Trainer,\n",
        "                          logging)\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             classification_report,\n",
        "                             confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:51:48.077481Z",
          "iopub.execute_input": "2025-02-04T12:51:48.077871Z",
          "iopub.status.idle": "2025-02-04T12:52:11.199565Z",
          "shell.execute_reply.started": "2025-02-04T12:51:48.077836Z",
          "shell.execute_reply": "2025-02-04T12:52:11.198606Z"
        },
        "id": "zz5dSi5BOPQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/kaggle/input/ai4bharat-indicsentiment/train.csv\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/ai4bharat-indicsentiment/test.csv\")\n",
        "train_df.fillna(\"Neutral\", inplace=True)\n",
        "\n",
        "train_df, test_df = train_test_split(train_df, test_size=0.1, stratify=train_df[[\"label\", \"language\"]], random_state=42)\n",
        "print(train_df.shape)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
        "\n",
        "# 1. Create Label Mapping\n",
        "unique_labels = dataset[\"train\"].unique(\"label\")\n",
        "num_labels = len(unique_labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:52:21.802722Z",
          "iopub.execute_input": "2025-02-04T12:52:21.803027Z",
          "iopub.status.idle": "2025-02-04T12:52:21.848854Z",
          "shell.execute_reply.started": "2025-02-04T12:52:21.803004Z",
          "shell.execute_reply": "2025-02-04T12:52:21.847974Z"
        },
        "id": "Fafge5zvOPQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Unique Labels: {unique_labels}\") # Debug print\n",
        "print(f\"Number of labels: {num_labels}\") # Debug print"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:52:31.112583Z",
          "iopub.execute_input": "2025-02-04T12:52:31.112889Z",
          "iopub.status.idle": "2025-02-04T12:52:31.117788Z",
          "shell.execute_reply.started": "2025-02-04T12:52:31.112868Z",
          "shell.execute_reply": "2025-02-04T12:52:31.116872Z"
        },
        "id": "Gu5THWW3OPQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt generation functions\n",
        "def generate_prompt(sent, lable):\n",
        "    return f\"\"\"\n",
        "            Classify the text into 'Positive', 'Negative', and return the answer as the predicted sentiment.\n",
        "text: {sent}\n",
        "label: {lable}\"\"\".strip()\n",
        "\n",
        "def generate_test_prompt(data_point):\n",
        "    return f\"\"\"\n",
        "            Classify the text into 'Positive', 'Negative', and return the answer as the predicted sentiment.\n",
        "text: {data_point}\n",
        "label: \"\"\".strip()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:54:08.609161Z",
          "iopub.execute_input": "2025-02-04T12:54:08.609519Z",
          "iopub.status.idle": "2025-02-04T12:54:08.613848Z",
          "shell.execute_reply.started": "2025-02-04T12:54:08.609489Z",
          "shell.execute_reply": "2025-02-04T12:54:08.612636Z"
        },
        "id": "RXmwke3kOPQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_name = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=\"float16\",\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"float16\",\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:52:54.114502Z",
          "iopub.execute_input": "2025-02-04T12:52:54.114855Z",
          "iopub.status.idle": "2025-02-04T12:54:02.90153Z",
          "shell.execute_reply.started": "2025-02-04T12:52:54.114826Z",
          "shell.execute_reply": "2025-02-04T12:54:02.900748Z"
        },
        "id": "7b3Ee6CGOPQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:54:02.902615Z",
          "iopub.execute_input": "2025-02-04T12:54:02.902852Z",
          "iopub.status.idle": "2025-02-04T12:54:03.491212Z",
          "shell.execute_reply.started": "2025-02-04T12:54:02.902831Z",
          "shell.execute_reply": "2025-02-04T12:54:03.490539Z"
        },
        "id": "I6kF0n1gOPQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = dataset[\"test\"].to_pandas()\n",
        "y_true = X_test.loc[:,'label']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:54:03.492575Z",
          "iopub.execute_input": "2025-02-04T12:54:03.492801Z",
          "iopub.status.idle": "2025-02-04T12:54:03.500967Z",
          "shell.execute_reply.started": "2025-02-04T12:54:03.492774Z",
          "shell.execute_reply": "2025-02-04T12:54:03.500049Z"
        },
        "id": "UI8Q0OnQOPQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test, model, tokenizer):\n",
        "    global unique_labels\n",
        "    y_pred = []\n",
        "    categories = unique_labels\n",
        "    model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "    for i in tqdm(range(len(test))):\n",
        "        prompt = test.iloc[i][\"sentence\"]\n",
        "        prompt = f\"\"\"\n",
        "            Classify the text into 'Positive', 'Negative', and return the answer as the predicted sentiment.\n",
        "text: {prompt}\n",
        "label: \"\"\".strip()\n",
        "\n",
        "        # Tokenize input\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        # Generate output from the model\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs, max_new_tokens=2, temperature=0.1)\n",
        "\n",
        "        # Decode output\n",
        "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract label from generated text\n",
        "        answer = answer.split(\"label:\")[-1].strip()\n",
        "\n",
        "        # Determine the predicted category\n",
        "        for category in categories:\n",
        "            if category.lower() in answer.lower():\n",
        "                y_pred.append(category)\n",
        "                break\n",
        "        else:\n",
        "            y_pred.append(\"none\")\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "y_pred = predict(X_test, model, tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:54:20.843664Z",
          "iopub.execute_input": "2025-02-04T12:54:20.843972Z",
          "iopub.status.idle": "2025-02-04T12:55:00.549923Z",
          "shell.execute_reply.started": "2025-02-04T12:54:20.843948Z",
          "shell.execute_reply": "2025-02-04T12:55:00.54914Z"
        },
        "id": "qdCmaumgOPQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "    global unique_labels\n",
        "    labels = unique_labels\n",
        "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
        "\n",
        "    def map_func(x):\n",
        "        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n",
        "\n",
        "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
        "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
        "    print(f'Accuracy: {accuracy:.3f}')\n",
        "\n",
        "    # Generate accuracy report\n",
        "    y_true = set(y_true_mapped)  # Get unique labels\n",
        "\n",
        "    for label in y_true:\n",
        "        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n",
        "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
        "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
        "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
        "        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n",
        "    print('\\nClassification Report:')\n",
        "    print(class_report)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n",
        "    print('\\nConfusion Matrix:')\n",
        "    print(conf_matrix)\n",
        "\n",
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:55:00.550945Z",
          "iopub.execute_input": "2025-02-04T12:55:00.551171Z",
          "iopub.status.idle": "2025-02-04T12:55:00.574155Z",
          "shell.execute_reply.started": "2025-02-04T12:55:00.551152Z",
          "shell.execute_reply": "2025-02-04T12:55:00.573391Z"
        },
        "id": "1mbOfDuJOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(examples):\n",
        "    inputs = [generate_prompt(sent, lable) for sent, lable in zip(examples[\"sentence\"], examples[\"label\"])]\n",
        "\n",
        "    tokenized_inputs = tokenizer(\n",
        "        inputs,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_fn, batched=True, batch_size=8, num_proc=4)\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.map(\n",
        "    lambda x: {\"length\": len(x[\"input_ids\"])},\n",
        "    num_proc=4\n",
        ").sort(\"length\")\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.select_columns([\"input_ids\", \"attention_mask\"])\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:55:00.575666Z",
          "iopub.execute_input": "2025-02-04T12:55:00.575902Z",
          "iopub.status.idle": "2025-02-04T12:55:04.133895Z",
          "shell.execute_reply.started": "2025-02-04T12:55:00.575883Z",
          "shell.execute_reply": "2025-02-04T12:55:04.133027Z"
        },
        "id": "NeJE7LbjOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import bitsandbytes as bnb\n",
        "\n",
        "def find_all_linear_names(model):\n",
        "    cls = bnb.nn.Linear4bit\n",
        "    lora_module_names = set()\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, cls):\n",
        "            names = name.split('.')\n",
        "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
        "        lora_module_names.remove('lm_head')\n",
        "    return list(lora_module_names)\n",
        "\n",
        "modules = find_all_linear_names(model)\n",
        "modules"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:55:04.135289Z",
          "iopub.execute_input": "2025-02-04T12:55:04.135531Z",
          "iopub.status.idle": "2025-02-04T12:55:04.143583Z",
          "shell.execute_reply.started": "2025-02-04T12:55:04.135507Z",
          "shell.execute_reply": "2025-02-04T12:55:04.142799Z"
        },
        "id": "BYAU9mQZOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir=\"llama-3.1-fine-tuned-model\"\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=16,\n",
        "    target_modules=['k_proj', 'v_proj', 'v_proj'],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T12:55:04.144602Z",
          "iopub.execute_input": "2025-02-04T12:55:04.144875Z",
          "iopub.status.idle": "2025-02-04T12:55:04.262338Z",
          "shell.execute_reply.started": "2025-02-04T12:55:04.144854Z",
          "shell.execute_reply": "2025-02-04T12:55:04.261583Z"
        },
        "id": "uNcYp_UDOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    # fp16_full_eval=False,  # Disable FP16 for evaluation\n",
        "    logging_steps=5,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=[\"none\"],\n",
        "    eval_accumulation_steps=4,\n",
        "    eval_steps=5\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T13:14:10.183475Z",
          "iopub.execute_input": "2025-02-04T13:14:10.183849Z",
          "iopub.status.idle": "2025-02-04T13:14:10.227657Z",
          "shell.execute_reply.started": "2025-02-04T13:14:10.183823Z",
          "shell.execute_reply": "2025-02-04T13:14:10.226736Z"
        },
        "id": "Rs5VG9beOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T13:14:11.246004Z",
          "iopub.execute_input": "2025-02-04T13:14:11.246382Z",
          "iopub.status.idle": "2025-02-04T13:44:20.466566Z",
          "shell.execute_reply.started": "2025-02-04T13:14:11.246351Z",
          "shell.execute_reply": "2025-02-04T13:44:20.465618Z"
        },
        "id": "QLfAI9QmOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X_test, peft_model, tokenizer)\n",
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T13:44:20.467805Z",
          "iopub.execute_input": "2025-02-04T13:44:20.468163Z",
          "iopub.status.idle": "2025-02-04T13:45:10.384946Z",
          "shell.execute_reply.started": "2025-02-04T13:44:20.468128Z",
          "shell.execute_reply": "2025-02-04T13:45:10.38398Z"
        },
        "id": "gY3whLLNOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    sentence = generate_test_prompt(text)\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(\"cuda\") # Move input to GPU\n",
        "    outputs = model.generate(**inputs, max_new_tokens=128) # Adjust max_new_tokens as needed\n",
        "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    output = decoded_output.split(\"label:\")[1]\n",
        "    return \"Positive\" if \"Positive\" in output else \"Negative\" if \"Negative\" in output else \"Neutral\"\n",
        "\n",
        "# Example\n",
        "example_text = \"जीवन अच्छा है।\"\n",
        "predicted_sentiment = predict_sentiment(example_text)\n",
        "\n",
        "print(f\"Sentence: {example_text}\")\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-04T13:05:57.315414Z",
          "iopub.execute_input": "2025-02-04T13:05:57.31571Z",
          "iopub.status.idle": "2025-02-04T13:06:07.775512Z",
          "shell.execute_reply.started": "2025-02-04T13:05:57.315687Z",
          "shell.execute_reply": "2025-02-04T13:06:07.774533Z"
        },
        "id": "uzSq4RlkOPQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "1GLTd694OPQt"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}