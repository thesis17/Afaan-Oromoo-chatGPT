{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 23812,
          "sourceType": "datasetVersion",
          "datasetId": 17810
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesis17/Afaan-Oromoo-chatGPT/blob/main/Copy_of_pneumonia_prediction_system_(CNN%2C99_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "paultimothymooney_chest_xray_pneumonia_path = kagglehub.dataset_download('paultimothymooney/chest-xray-pneumonia')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "qwzuft-lSfU5"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pneumonia Detection on Chest X-ray Images Using Deep Learning\n",
        "\n",
        "This project for **[Data Science for the Public Good program](https://www.kodluyoruz.org/bootcamp/data-science-for-the-public-good-istanbul-ankara/)**\n",
        "\n",
        "The dataset of this project is obtained from the [Kaggle - Chest X-ray Images(Pneumonia](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia)\n",
        "\n",
        "Note: The data sets to be used in the project comply with the health-ethical rules and are suitable for use as a license.\n"
      ],
      "metadata": {
        "id": "lwGs5lXQElzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. BUSINESS UNDERSTANDING\n",
        "\n",
        "\n",
        "### Context\n",
        "![Example of Chest X-rays in patients](https://i.imgur.com/jZqpV51.png)\n",
        "\n",
        "The normal chest X-ray(left panel) depicts clear lungs without any areas of abnormal opacification in the image.\n",
        "Bacterical pneumonia (middle panel) typically exhibits a focal lobar consolidation, in this case in the right upper lobe (white arrows), whereas viral pneumonia(right panel) manifets with a more diffuse \"interstitial\" pattern in both lungs.\n",
        "\n",
        "### Content\n",
        "\n",
        "The dataset is organized into 3 folders (train, test, val) and contains subfolders of each image category (Pneumonia / Normal). There are 5,863 X-Ray images (JPEG) and 2 categories(Pneumonia/Normal)\n",
        "\n",
        "Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children’s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients’ routine clinical care.\n",
        "\n",
        "For the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5ZcLiBgXRdVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. DATA UNDERSTANDING"
      ],
      "metadata": {
        "id": "u_4JpH1ORrtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation the Libraries"
      ],
      "metadata": {
        "id": "jF9VGV5GUNL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ],
      "metadata": {
        "id": "4Lx5bgmyEldv",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:03:34.449805Z",
          "iopub.execute_input": "2025-06-14T18:03:34.450113Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries\n"
      ],
      "metadata": {
        "id": "_Ei0whwTW0oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "import opendatasets as od\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "import random\n",
        "from pathlib import Path #to be able to use functions using path\n",
        "\n",
        "\n",
        "# Data science tools\n",
        "import pandas as pd # data processing\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "# Tensorflow for GPU\n",
        "import tensorflow as tf\n",
        "from tensorflow.compat.v1 import Session, ConfigProto, set_random_seed\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Keras library for Modeling\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "# OpenCV\n",
        "import cv2\n",
        "\n",
        "# Resize images\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Scikit-learn library\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Visualizations\n",
        "from PIL import Image\n",
        "import imgaug as aug\n",
        "import imgaug.augmenters as iaa\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mimg # images\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "lzrFSBlUEc6b",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.201209Z",
          "iopub.execute_input": "2025-06-14T18:01:30.201466Z",
          "iopub.status.idle": "2025-06-14T18:01:30.284093Z",
          "shell.execute_reply.started": "2025-06-14T18:01:30.201444Z",
          "shell.execute_reply": "2025-06-14T18:01:30.280249Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the data"
      ],
      "metadata": {
        "id": "rymkwwadXOw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.285026Z",
          "iopub.status.idle": "2025-06-14T18:01:30.285526Z",
          "shell.execute_reply": "2025-06-14T18:01:30.285376Z"
        },
        "_kg_hide-output": true,
        "id": "ZVAiYdCgSfU_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories where you'll store the data\n",
        "base_dir = Path(\"chest-xray-pneumonia/chest_xray/chest_xray/\")\n"
      ],
      "metadata": {
        "id": "fS3NOxl5X4go",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.286106Z",
          "iopub.status.idle": "2025-06-14T18:01:30.286437Z",
          "shell.execute_reply": "2025-06-14T18:01:30.286309Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for the training, validation, and test splits\n",
        "train_dir = Path(\"../input/chest-xray-pneumonia/chest_xray/train\")\n",
        "val_dir = Path(\"../input/chest-xray-pneumonia/chest_xray/val\")\n",
        "test_dir = Path(\"../input/chest-xray-pneumonia/chest_xray/test\")"
      ],
      "metadata": {
        "id": "q-yHuFHbYkcV",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.286965Z",
          "iopub.status.idle": "2025-06-14T18:01:30.287287Z",
          "shell.execute_reply": "2025-06-14T18:01:30.287128Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing the environment CPU to GPU (Check the GPU Environment)"
      ],
      "metadata": {
        "id": "3BgdxrWIYpnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "uQ5gXkoj98EO",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.288595Z",
          "iopub.status.idle": "2025-06-14T18:01:30.289038Z",
          "shell.execute_reply": "2025-06-14T18:01:30.288893Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z9Bygc7o9ugy",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "jLfsGrt7cNYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Loading for Train Dataset"
      ],
      "metadata": {
        "id": "2g3r0Jb0Y7S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "id": "dAqdeUjqYxbP",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.289773Z",
          "iopub.status.idle": "2025-06-14T18:01:30.290034Z",
          "shell.execute_reply": "2025-06-14T18:01:30.289929Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_normal_dir = train_dir /\"NORMAL\" #to set the path to the normals in train set\n",
        "train_pneumonia_dir = train_dir /\"PNEUMONIA\" #to set the path to the pneumonias in train set"
      ],
      "metadata": {
        "id": "znQnkTOsZCAG",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.29119Z",
          "iopub.status.idle": "2025-06-14T18:01:30.291609Z",
          "shell.execute_reply": "2025-06-14T18:01:30.291497Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Loading for Validation Dataset"
      ],
      "metadata": {
        "id": "5n1PH8xsZkaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(val_dir)"
      ],
      "metadata": {
        "id": "wXNqOwyGZKlN",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.292542Z",
          "iopub.status.idle": "2025-06-14T18:01:30.292751Z",
          "shell.execute_reply": "2025-06-14T18:01:30.292668Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "valid_normal_dir = val_dir /\"NORMAL\" #to set the path to the normals in validation set\n",
        "valid_pneumonia_dir = val_dir /\"PNEUMONIA\" #to set the path to the pneumonias in validation set"
      ],
      "metadata": {
        "id": "Currj5plZ0IN",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.293717Z",
          "iopub.status.idle": "2025-06-14T18:01:30.294217Z",
          "shell.execute_reply": "2025-06-14T18:01:30.294018Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Loading for Test Dataset"
      ],
      "metadata": {
        "id": "Z5GonrRTaGZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(test_dir)"
      ],
      "metadata": {
        "id": "7gFp6VgRaMoG",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.294976Z",
          "iopub.status.idle": "2025-06-14T18:01:30.295222Z",
          "shell.execute_reply": "2025-06-14T18:01:30.295116Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal_dir = test_dir /\"NORMAL\" #to set the path to the normals in test set\n",
        "test_pneumonia_dir = test_dir /\"PNEUMONIA\" #to set the path to the pneumonias in test set"
      ],
      "metadata": {
        "id": "a5IoZ328aRrI",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.296149Z",
          "iopub.status.idle": "2025-06-14T18:01:30.296714Z",
          "shell.execute_reply": "2025-06-14T18:01:30.296556Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Labeling"
      ],
      "metadata": {
        "id": "5a-ebhfLbSfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting the dataset for training"
      ],
      "metadata": {
        "id": "xynCWFxrcFbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_normal= train_normal_dir.glob(\"*.jpeg\") #to take the normal images from train set\n",
        "train_pneumonia=train_pneumonia_dir.glob(\"*.jpeg\") #to take the pneumonia images from the train set\n",
        "train_set=[]#to add all the train data into one list, we created a blank list"
      ],
      "metadata": {
        "id": "hyUUKBG8cKet",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.297423Z",
          "iopub.status.idle": "2025-06-14T18:01:30.297714Z",
          "shell.execute_reply": "2025-06-14T18:01:30.297591Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for img in train_normal: #to add every image of normals in trainset to the list\n",
        "  train_set.append((img, 0)) #we add 0 with normal images as label\n",
        "for img in train_pneumonia:#to add every image of pneumonias in trainset to the list\n",
        "  train_set.append((img, 1)) #we add 1 with pneumonia images as label"
      ],
      "metadata": {
        "id": "Eh8FSMp-eEjB",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.298464Z",
          "iopub.status.idle": "2025-06-14T18:01:30.298764Z",
          "shell.execute_reply": "2025-06-14T18:01:30.298634Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set[:15]) #to check what our list look like"
      ],
      "metadata": {
        "id": "KEP_47cmeGvG",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.299466Z",
          "iopub.status.idle": "2025-06-14T18:01:30.299762Z",
          "shell.execute_reply": "2025-06-14T18:01:30.299637Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=pd.DataFrame(train_set, columns=[\"image\", \"label\"], index=None)#to create a dataframe from the list, so that we can use dataframe features"
      ],
      "metadata": {
        "id": "uG_VpU8aeZJx",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.30037Z",
          "iopub.status.idle": "2025-06-14T18:01:30.300657Z",
          "shell.execute_reply": "2025-06-14T18:01:30.300532Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.head() #to see the first 5 rows of our dataframe, only normals are shown since we added them first."
      ],
      "metadata": {
        "id": "Pj1RIt1kedmi",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.301835Z",
          "iopub.status.idle": "2025-06-14T18:01:30.302217Z",
          "shell.execute_reply": "2025-06-14T18:01:30.302077Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_set=train_set.sample(frac=1) #to shuffle all the rows in dataframe so that we can see normal and pneumonia in random\n",
        "train_set=train_set.reset_index(drop=True) #to set the indexes as if first time\n",
        "train_set.head()"
      ],
      "metadata": {
        "id": "VcDtD9MCejkP",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.302903Z",
          "iopub.status.idle": "2025-06-14T18:01:30.303221Z",
          "shell.execute_reply": "2025-06-14T18:01:30.303088Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting the dataset for valdiation"
      ],
      "metadata": {
        "id": "DT33vScEenOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_normal= valid_normal_dir.glob(\"*.jpeg\") #to take the normal images from validation set\n",
        "valid_pneumonia=valid_pneumonia_dir.glob(\"*.jpeg\") #to take the pneumonia images from the validation set\n",
        "valid_set=[] #to add all the validation data into one list, we created a blank list"
      ],
      "metadata": {
        "id": "JNQTffhaeszJ",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.303985Z",
          "iopub.status.idle": "2025-06-14T18:01:30.304325Z",
          "shell.execute_reply": "2025-06-14T18:01:30.304159Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for img in valid_normal: #to add every image of normals in validationset to the list\n",
        "  valid_set.append((img, 0)) #we add 0 with normal images as label\n",
        "for img in valid_pneumonia:#to add every image of pneumonias in validationset to the list\n",
        "  valid_set.append((img, 1)) #we add 1 with pneumonia images as label\n"
      ],
      "metadata": {
        "id": "OAo5puWTevSS",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.305182Z",
          "iopub.status.idle": "2025-06-14T18:01:30.305523Z",
          "shell.execute_reply": "2025-06-14T18:01:30.305377Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_set[:15]) #to check what our list look like"
      ],
      "metadata": {
        "id": "zvsjCEeue9zW",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.306217Z",
          "iopub.status.idle": "2025-06-14T18:01:30.306552Z",
          "shell.execute_reply": "2025-06-14T18:01:30.30642Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "valid_set=pd.DataFrame(valid_set, columns=[\"image\", \"label\"], index=None)#to create a dataframe from the list, so that we can use dataframe features\n",
        "valid_set.head() #to see the first 5 rows of our dataframe, only normals are shown since we added them first."
      ],
      "metadata": {
        "id": "-0Pueu30e_My",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.307085Z",
          "iopub.status.idle": "2025-06-14T18:01:30.307461Z",
          "shell.execute_reply": "2025-06-14T18:01:30.307313Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "valid_set=valid_set.sample(frac=1) #to shuffle all the rows in dataframe so that we can see normal and pneumonia in random\n",
        "valid_set=valid_set.reset_index(drop=True) #to set the indexes as if first time\n",
        "valid_set.head()"
      ],
      "metadata": {
        "id": "H3so5_mNfC2b",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.307838Z",
          "iopub.status.idle": "2025-06-14T18:01:30.308164Z",
          "shell.execute_reply": "2025-06-14T18:01:30.308026Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting the dataset for test"
      ],
      "metadata": {
        "id": "COm_d3nofFLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal= test_normal_dir.glob(\"*.jpeg\") #to take the normal images from test set\n",
        "test_pneumonia=test_pneumonia_dir.glob(\"*.jpeg\") #to take the pneumonia images from the test set\n",
        "test_set=[]#to add all the test data into one list, we created a blank list"
      ],
      "metadata": {
        "id": "sYXjCnsTfJWd",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.309331Z",
          "iopub.status.idle": "2025-06-14T18:01:30.309834Z",
          "shell.execute_reply": "2025-06-14T18:01:30.309647Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for img in test_normal: #to add every image of normals in test set to the list\n",
        "  test_set.append((img, 0)) #we add 0 with normal images as label\n",
        "for img in test_pneumonia:#to add every image of pneumonias in test set to the list\n",
        "  test_set.append((img, 1)) #we add 1 with pneumonia images as label\n"
      ],
      "metadata": {
        "id": "Z7x4UxD-fLk0",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.310832Z",
          "iopub.status.idle": "2025-06-14T18:01:30.31116Z",
          "shell.execute_reply": "2025-06-14T18:01:30.311018Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set[:15]) #to check what our list look like"
      ],
      "metadata": {
        "id": "Rk0d0M_GfNV0",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.311909Z",
          "iopub.status.idle": "2025-06-14T18:01:30.312218Z",
          "shell.execute_reply": "2025-06-14T18:01:30.312082Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_set=pd.DataFrame(test_set, columns=[\"image\", \"label\"], index=None)#to create a dataframe from the list, so that we can use dataframe features\n",
        "test_set.head() #to see the first 5 rows of our dataframe, only normals are shown since we added them first."
      ],
      "metadata": {
        "id": "rgtIJBUGfOdy",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.312814Z",
          "iopub.status.idle": "2025-06-14T18:01:30.313099Z",
          "shell.execute_reply": "2025-06-14T18:01:30.312974Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_set=test_set.sample(frac=1) #to shuffle all the rows in dataframe so that we can see normal and pneumonia in random\n",
        "test_set=test_set.reset_index(drop=True) #to set the indexes as if first time\n",
        "test_set.head()"
      ],
      "metadata": {
        "id": "z77qTEvzfQXR",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.313576Z",
          "iopub.status.idle": "2025-06-14T18:01:30.313878Z",
          "shell.execute_reply": "2025-06-14T18:01:30.313733Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visualization"
      ],
      "metadata": {
        "id": "4ItcSpm6fuaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normal Image\n",
        "train_normal_count= train_set.loc[train_set[\"label\"]==0][\"image\"].count()\n",
        "print(\"Total number of normal images:\", train_normal_count)"
      ],
      "metadata": {
        "id": "YhKMhzoTfzwE",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.314548Z",
          "iopub.status.idle": "2025-06-14T18:01:30.314738Z",
          "shell.execute_reply": "2025-06-14T18:01:30.314661Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Pneumonia Image\n",
        "train_pneumonia_count= train_set.loc[train_set[\"label\"]==1][\"image\"].count()\n",
        "print(\"Total number of pneumonia images:\", train_pneumonia_count)"
      ],
      "metadata": {
        "id": "9KT133auf__b",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.315418Z",
          "iopub.status.idle": "2025-06-14T18:01:30.315659Z",
          "shell.execute_reply": "2025-06-14T18:01:30.315573Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normal / Pneumonia Image Visualization for Train Dataset"
      ],
      "metadata": {
        "id": "Y5-82tRVhEOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get few samples for both the classes\n",
        "pneumonia_samples = (train_set[train_set[\"label\"] == 1][\"image\"].iloc[:5]).tolist()\n",
        "normal_samples = (train_set[train_set[\"label\"] == 0][\"image\"].iloc[:5]).tolist()\n",
        "\n",
        "# Concate the data in a single list and del the above two list\n",
        "samples = pneumonia_samples + normal_samples\n",
        "del pneumonia_samples, normal_samples\n",
        "\n",
        "# Plot the data\n",
        "f, ax = plt.subplots(2,5, figsize = (30,10))\n",
        "for i in range(10):\n",
        "    img = imread(samples[i])\n",
        "    ax[i//5, i % 5].imshow(img, cmap='gray')\n",
        "    if i < 5:\n",
        "        ax[i//5, i % 5].set_title(\"PNEUMONIA\")\n",
        "    else:\n",
        "        ax[i//5, i % 5].set_title(\"NORMAL\")\n",
        "    ax[i//5, i % 5].axis('off')\n",
        "    ax[i//5, i % 5].set_aspect('auto')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6TysST6W6gNj",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.316126Z",
          "iopub.status.idle": "2025-06-14T18:01:30.316383Z",
          "shell.execute_reply": "2025-06-14T18:01:30.316281Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting the Data Distribution"
      ],
      "metadata": {
        "id": "WQP2GFZKkcEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig1,ax1= plt.subplots()\n",
        "sizes=[train_normal_count, train_pneumonia_count]\n",
        "ax1.pie(sizes, startangle=46 ,labels=[\"Normal lungs\",\"Pneumonic lungs\"], autopct=\"%1.1f%%\", shadow=True, colors=[\"b\",\"r\"])\n",
        "ax1.axis(\"equal\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jA6LH_Prkptl",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.317006Z",
          "iopub.status.idle": "2025-06-14T18:01:30.317221Z",
          "shell.execute_reply": "2025-06-14T18:01:30.317135Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fig2, ax2=plt.subplots()\n",
        "ax2.bar(height=sizes, x=[\"Normal lungs\", \"Pneumonic lungs\"], color=[\"blue\", \"red\"])\n",
        "plt.title(\"Case Distribution\")"
      ],
      "metadata": {
        "id": "ipdNN9dRk5yD",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.317676Z",
          "iopub.status.idle": "2025-06-14T18:01:30.317913Z",
          "shell.execute_reply": "2025-06-14T18:01:30.317799Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to this result, we have imbalanced image dataset. We will increase the \"Normal\" image dataset using Data Augmentation to correct this imbalance."
      ],
      "metadata": {
        "id": "jCkoB6LxnNcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "FsO-U5g4lUlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Distribution"
      ],
      "metadata": {
        "id": "3l21GFC6IS2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "img_size = 150\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def get_training_data(data_dir, labels, img_size=150):\n",
        "    images = []\n",
        "    targets = []\n",
        "\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
        "                images.append(resized_arr)\n",
        "                targets.append(class_num)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(targets)\n"
      ],
      "metadata": {
        "id": "R9XliorclTn9",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.318511Z",
          "iopub.status.idle": "2025-06-14T18:01:30.318779Z",
          "shell.execute_reply": "2025-06-14T18:01:30.318681Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = get_training_data(train_dir, labels)\n",
        "X_test, y_test = get_training_data(test_dir, labels)\n",
        "X_val, y_val = get_training_data(val_dir, labels)\n"
      ],
      "metadata": {
        "id": "IijGrdAzl9tG",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.319292Z",
          "iopub.status.idle": "2025-06-14T18:01:30.319549Z",
          "shell.execute_reply": "2025-06-14T18:01:30.319428Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''# initialize multiple lists\n",
        "X_train, X_val, X_test = ([], ) * 3\n",
        "y_train, y_val, y_test = ([], ) * 3\n",
        "\n",
        "for feature, label in train:\n",
        "    X_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "    X_val.append(feature)\n",
        "    y_val.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "    X_test.append(feature)\n",
        "    y_test.append(label)'''"
      ],
      "metadata": {
        "id": "6aQb-S-VoEfr",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.319985Z",
          "iopub.status.idle": "2025-06-14T18:01:30.320211Z",
          "shell.execute_reply": "2025-06-14T18:01:30.320105Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform a grayscale normalization to reduce the effect of illumination's differences. Moreover the CNN converges faster on [0..1] data than on [0..255]."
      ],
      "metadata": {
        "id": "uZsqtDNUoJqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Normalization"
      ],
      "metadata": {
        "id": "D7g3HKC0oPbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train) /255\n",
        "X_val = np.array(X_val) / 255\n",
        "X_test = np.array(X_test) / 255"
      ],
      "metadata": {
        "id": "NIoA_KMJoJBs",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.320643Z",
          "iopub.status.idle": "2025-06-14T18:01:30.32085Z",
          "shell.execute_reply": "2025-06-14T18:01:30.32076Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reshaping the data for deep learning model"
      ],
      "metadata": {
        "id": "38UZzZOgojfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape (-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_val = X_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "X_test = X_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "OrxPHki5opZ8",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.321249Z",
          "iopub.status.idle": "2025-06-14T18:01:30.321476Z",
          "shell.execute_reply": "2025-06-14T18:01:30.321401Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. DATA AUGMENTATION"
      ],
      "metadata": {
        "id": "Mmk3KQNfpLza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid the overfitting problem, we need to artificially expand our dataset. We can further enlarge your existing dataset. The idea is to manipulate the training data with small transformations to reproduce the variations. Approaches that modify the training data to change the sequence representation while keeping the label the same are known as data augmentation techniques. Some popular magnifications people use are grayscales, horizontal flips, vertical flips, random crops, dithering, offsets, rotations, and much more. By applying just a few of these transformations to our training data, we can easily double or triple the number of training samples and create a very robust model."
      ],
      "metadata": {
        "id": "7kPl28roUVgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Train Generator"
      ],
      "metadata": {
        "id": "9heZPOOk3m6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize and augment images\n",
        "image_generator = ImageDataGenerator(\n",
        "  featurewise_center = False, # set input mean to 0 over the dataset\n",
        "  samplewise_center = False, # set each sample mean to 0\n",
        "  featurewise_std_normalization = False, #divide inputs by std of the dataset\n",
        "  samplewise_std_normalization = False, # divide each input by its std\n",
        "  zca_whitening=False,  # apply ZCA whitening\n",
        "  rotation_range =30, #randomly rotate images in the range\n",
        "  zoom_range = 0.2, #randomly zoom image\n",
        "  width_shift_range = 0.1, #randomly shift images horizontally\n",
        "  height_shift_range = 0.1, #randomly shift images vertically\n",
        "  horizontal_flip = True, #randomly flip images\n",
        "  vertical_flip = False) #randomly flip images\n",
        "\n",
        "image_generator.fit(X_train)"
      ],
      "metadata": {
        "id": "4ZVgsvCZMaJx",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.321936Z",
          "iopub.status.idle": "2025-06-14T18:01:30.322195Z",
          "shell.execute_reply": "2025-06-14T18:01:30.322078Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Assuming 'train_dir' and 'val_dir' are your directories for training and validation images\n",
        "image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = image_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Resize images to 150x150\n",
        "    color_mode='grayscale',  # Use 'rgb' if the images are in color\n",
        "    class_mode='binary',  # Change according to your task (e.g., 'categorical' or 'binary')\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = image_generator.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(150, 150),\n",
        "    color_mode='grayscale',\n",
        "    class_mode='binary',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "# Assuming 'test_dir' is your test directory\n",
        "test_generator = image_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),  # Resize to match input size\n",
        "    color_mode='grayscale',  # Use 'rgb' for color images\n",
        "    class_mode='binary',  # Set according to your task ('binary' or 'categorical')\n",
        "    batch_size=32,\n",
        "    shuffle=False  # Typically, we don't shuffle the test data\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.322848Z",
          "iopub.status.idle": "2025-06-14T18:01:30.323057Z",
          "shell.execute_reply": "2025-06-14T18:01:30.322963Z"
        },
        "id": "0JnwDXW9SfVK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the data augmentation, we choosed to:\n",
        "\n",
        "1. Randomly rotate some training images by 30 degrees\n",
        "2. Randomly Zoom by 20% saome training images\n",
        "3. Randomly shift imags horizontally by 10% of the width\n",
        "4. Randomly shift images vertically by 10% of the height\n",
        "5. Randomly flip images horizontally\n",
        "\n"
      ],
      "metadata": {
        "id": "DUJ1Vtd7ShWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D. DATA MODELLING"
      ],
      "metadata": {
        "id": "2GUVlj7fynYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.1 Building CNN Model"
      ],
      "metadata": {
        "id": "RZ6h5r_Pslmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import MaxPooling2D\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.323603Z",
          "iopub.status.idle": "2025-06-14T18:01:30.323829Z",
          "shell.execute_reply": "2025-06-14T18:01:30.323747Z"
        },
        "id": "xvWkH4VnSfVL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 128 , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
        "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rvA5h2Ppslmz",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.324242Z",
          "iopub.status.idle": "2025-06-14T18:01:30.324474Z",
          "shell.execute_reply": "2025-06-14T18:01:30.324392Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.3, min_lr=0.000001)"
      ],
      "metadata": {
        "id": "T_QvIxtUslmz",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.325109Z",
          "iopub.status.idle": "2025-06-14T18:01:30.32536Z",
          "shell.execute_reply": "2025-06-14T18:01:30.325232Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.325807Z",
          "iopub.status.idle": "2025-06-14T18:01:30.326022Z",
          "shell.execute_reply": "2025-06-14T18:01:30.32594Z"
        },
        "id": "Mef8ww6JSfVM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[learning_rate_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "id": "N4acIgcVslmz",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.326627Z",
          "iopub.status.idle": "2025-06-14T18:01:30.326876Z",
          "shell.execute_reply": "2025-06-14T18:01:30.326762Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.327376Z",
          "iopub.status.idle": "2025-06-14T18:01:30.327634Z",
          "shell.execute_reply": "2025-06-14T18:01:30.327501Z"
        },
        "id": "V3OBdvlkSfVM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
      ],
      "metadata": {
        "id": "MiNqYWvYslm0",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.328089Z",
          "iopub.status.idle": "2025-06-14T18:01:30.328344Z",
          "shell.execute_reply": "2025-06-14T18:01:30.328206Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E.EVALUATION"
      ],
      "metadata": {
        "id": "kfKNzsPMslm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [i for i in range(15)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
        "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
        "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
        "ax[1].set_title('Testing Accuracy & Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iFhSSC15slm0",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.329339Z",
          "iopub.status.idle": "2025-06-14T18:01:30.329731Z",
          "shell.execute_reply": "2025-06-14T18:01:30.329587Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "predictions = predictions.reshape(1, -1)[0]\n",
        "predictions[:15]\n"
      ],
      "metadata": {
        "id": "wjs_5Hw_slm0",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.330472Z",
          "iopub.status.idle": "2025-06-14T18:01:30.330734Z",
          "shell.execute_reply": "2025-06-14T18:01:30.330615Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
      ],
      "metadata": {
        "id": "WvrK1P_9slm1",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.33122Z",
          "iopub.status.idle": "2025-06-14T18:01:30.331471Z",
          "shell.execute_reply": "2025-06-14T18:01:30.331381Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, predictions)\n",
        "cm\n"
      ],
      "metadata": {
        "id": "1Zhbqovzslm1",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.331989Z",
          "iopub.status.idle": "2025-06-14T18:01:30.332217Z",
          "shell.execute_reply": "2025-06-14T18:01:30.332114Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cm = pd.DataFrame(cm, index=['0', '1'], columns=['0', '1'])\n"
      ],
      "metadata": {
        "id": "PsBBdyXbslm1",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.332693Z",
          "iopub.status.idle": "2025-06-14T18:01:30.332901Z",
          "shell.execute_reply": "2025-06-14T18:01:30.332819Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = labels,yticklabels = labels)"
      ],
      "metadata": {
        "id": "e7Dw9tvjslm1",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.333322Z",
          "iopub.status.idle": "2025-06-14T18:01:30.333579Z",
          "shell.execute_reply": "2025-06-14T18:01:30.333461Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "correct = np.nonzero(predictions == y_test)[0]\n",
        "incorrect = np.nonzero(predictions != y_test)[0]\n"
      ],
      "metadata": {
        "id": "fnKvwi4cslm1",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.334181Z",
          "iopub.status.idle": "2025-06-14T18:01:30.334489Z",
          "shell.execute_reply": "2025-06-14T18:01:30.334365Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F. PROOF"
      ],
      "metadata": {
        "id": "9Dlksggsslm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F.1 Some of the Correctly Predicted Classes"
      ],
      "metadata": {
        "id": "FU1lPChGslm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for c in correct[:5]:\n",
        "    plt.subplot(3, 2, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(X_test[c].reshape(150, 150), cmap=\"gray\", interpolation='none')\n",
        "    plt.title(\"Predicted Class {},Actual Class {}\".format(\n",
        "        predictions[c], y_test[c]))\n",
        "    plt.tight_layout()\n",
        "    i += 1\n"
      ],
      "metadata": {
        "id": "GsUdc5Gvslm2",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.334997Z",
          "iopub.status.idle": "2025-06-14T18:01:30.335193Z",
          "shell.execute_reply": "2025-06-14T18:01:30.335115Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F.2 Some of the Incorrectly Predicted Class"
      ],
      "metadata": {
        "id": "tb85u0whslm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for c in incorrect[:5]:\n",
        "    plt.subplot(3, 2, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(X_test[c].reshape(150, 150), cmap=\"gray\", interpolation='none')\n",
        "    plt.title(\"Predicted Class {},Actual Class {}\".format(predictions[c], y_test[c]))\n",
        "    plt.tight_layout()\n",
        "    i += 1\n"
      ],
      "metadata": {
        "id": "ToPesQVNslm3",
        "execution": {
          "iopub.status.busy": "2025-06-14T18:01:30.335661Z",
          "iopub.status.idle": "2025-06-14T18:01:30.335846Z",
          "shell.execute_reply": "2025-06-14T18:01:30.335771Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}