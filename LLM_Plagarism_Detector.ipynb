{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 61542,
          "databundleVersionId": 7516023,
          "sourceType": "competition"
        },
        {
          "sourceId": 6867914,
          "sourceType": "datasetVersion",
          "datasetId": 3946973
        },
        {
          "sourceId": 6890527,
          "sourceType": "datasetVersion",
          "datasetId": 3942644
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "LLM Plagarism Detector",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thesis17/Afaan-Oromoo-chatGPT/blob/main/LLM_Plagarism_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "alejopaullier_argugpt_path = kagglehub.dataset_download('alejopaullier/argugpt')\n",
        "thedrcat_daigt_proper_train_dataset_path = kagglehub.dataset_download('thedrcat/daigt-proper-train-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Ag0rWB2ypBqz"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install libraries**"
      ],
      "metadata": {
        "id": "xsNteKeRpBq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wurlitzer"
      ],
      "metadata": {
        "trusted": true,
        "id": "HR8ShsOCpBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras_nlp==0.6.3 keras-core==0.1.7"
      ],
      "metadata": {
        "trusted": true,
        "id": "kl3Dp7pWpBq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "Cj_X0oSJpBq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "trusted": true,
        "id": "g73IaPADpBq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name cudnn_version.h 2>/dev/null"
      ],
      "metadata": {
        "trusted": true,
        "id": "-_bLnqpApBq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2"
      ],
      "metadata": {
        "trusted": true,
        "id": "68xeF9OmpBq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # \"jax\" or \"tensorflow\" or \"torch\"\n",
        "#os.environ[\"WANDB_SILENT\"] = \"false\" # for wandb\n",
        "\n",
        "import keras_nlp\n",
        "import keras_core as keras\n",
        "import keras_core.backend as K\n",
        "\n",
        "\n",
        "import torch\n",
        "# import jax\n",
        "import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# import tensorflow.keras.backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "cmap = mpl.cm.get_cmap('coolwarm')"
      ],
      "metadata": {
        "trusted": true,
        "id": "76p58rASpBq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow:\", tf.__version__)\n",
        "# print(\"JAX:\", jax.__version__)\n",
        "print(\"Keras:\", keras.__version__)\n",
        "print(\"KerasNLP:\", keras_nlp.__version__)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_fEgZllypBq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuration**"
      ],
      "metadata": {
        "id": "bLwKnYfApBq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    verbose = 0  # Verbosity\n",
        "\n",
        "    wandb = True  # Weights & Biases logging\n",
        "    competition = 'llm-detect-ai-generated-text'  # Competition name\n",
        "    _wandb_kernel = 'awsaf49'  # WandB kernel\n",
        "    comment = 'DebertaV3-MaxSeq_200-ext_s-torch'  # Comment description\n",
        "\n",
        "    preset = \"deberta_v3_base_en\"  # Name of pretrained models\n",
        "    sequence_length = 200  # Input sequence length\n",
        "\n",
        "    device = 'TPU'  # Device\n",
        "\n",
        "    seed = 42  # Random seed\n",
        "\n",
        "    num_folds = 5  # Total folds\n",
        "    selected_folds = [0, 1]  # Folds to train on\n",
        "\n",
        "    epochs = 3 # Training epochs\n",
        "    batch_size = 3  # Batch size\n",
        "    drop_remainder = True  # Drop incomplete batches\n",
        "    cache = True # Caches data after one iteration, use only with `TPU` to avoid OOM\n",
        "\n",
        "    scheduler = 'cosine'  # Learning rate scheduler\n",
        "\n",
        "    class_names = [\"real\", \"fake\"]  # Class names [A, B, C, D, E]\n",
        "    num_classes = len(class_names)  # Number of classes\n",
        "    class_labels = list(range(num_classes))  # Class labels [0, 1, 2, 3, 4]\n",
        "    label2name = dict(zip(class_labels, class_names))  # Label to class name mapping\n",
        "    name2label = {v: k for k, v in label2name.items()}  # Class name to label mapping"
      ],
      "metadata": {
        "trusted": true,
        "id": "H_3kdY6xpBq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.set_random_seed(CFG.seed)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2m0R3UVMpBq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hardware**"
      ],
      "metadata": {
        "id": "rZK5ndRvpBq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    \"Detect and intializes GPU/TPU automatically\"\n",
        "    try:\n",
        "        # detect and init the TPU\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "\n",
        "        # instantiate a distribution strategy\n",
        "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "        strategy = tf.distribute.TPUStrategy(tpu)\n",
        "        print(f'> Running on TPU', tpu.master(), end=' | ')\n",
        "        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n",
        "        device=CFG.device\n",
        "    except:\n",
        "        # If TPU is not available, detect GPUs\n",
        "        gpus = tf.config.list_logical_devices('GPU')\n",
        "        ngpu = len(gpus)\n",
        "         # Check number of GPUs\n",
        "        if ngpu:\n",
        "            # Set GPU strategy\n",
        "            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n",
        "            # Print GPU details\n",
        "            print(\"> Running on GPU\", end=' | ')\n",
        "            print(\"Num of GPUs: \", ngpu)\n",
        "            device='GPU'\n",
        "        else:\n",
        "            # If no GPUs are available, use CPU\n",
        "            print(\"> Running on CPU\")\n",
        "            strategy = tf.distribute.get_strategy()\n",
        "            device='CPU'\n",
        "    return strategy, device"
      ],
      "metadata": {
        "trusted": true,
        "id": "5291TLVbpBq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GPU/TPU/TPU-VM\n",
        "strategy, CFG.device = get_device()\n",
        "CFG.replicas = strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "trusted": true,
        "id": "3srPaNWFpBq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the Datatset**"
      ],
      "metadata": {
        "id": "AS8YIwT8pBq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = '/kaggle/input/llm-detect-ai-generated-text/'"
      ],
      "metadata": {
        "trusted": true,
        "id": "YcQf1C_kpBq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f'{BASE_PATH}/train_essays.csv')  # Read CSV file into a DataFrame\n",
        "df['label'] = df.generated.copy()\n",
        "df['name'] = df.generated.map(CFG.label2name)  # Map answer labels using name-to-label mapping\n",
        "\n",
        "# Display information about the train data\n",
        "print(\"# Train Data: {:,}\".format(len(df)))\n",
        "print(\"# Sample:\")\n",
        "display(df.head(2))\n",
        "\n",
        "# Show distribution of answers using a bar plot\n",
        "plt.figure(figsize=(8, 4))\n",
        "df.name.value_counts().plot.bar(color=[cmap(0.0), cmap(0.25), cmap(0.65), cmap(0.9), cmap(1.0)])\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class distribution for Train Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2xo840RnpBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Addressing the Class Imbalance by concatenating external datasets**"
      ],
      "metadata": {
        "id": "4PFWvPvupBq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load external data\n",
        "ext_df1 = pd.read_csv('/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv')\n",
        "ext_df2 = pd.read_csv('/kaggle/input/argugpt/argugpt.csv')[['id', 'text', 'model']]\n",
        "\n",
        "ext_df2.rename(columns={'model': 'source'}, inplace=True)\n",
        "ext_df2['label'] = 1\n",
        "\n",
        "ext_df = pd.concat([\n",
        "    ext_df1[ext_df1.source == 'persuade_corpus'].sample(10000),\n",
        "    ext_df1[ext_df1.source != 'persuade_corpus'],\n",
        "    ext_df2,\n",
        "])\n",
        "ext_df['name'] = ext_df.label.map(CFG.label2name)\n",
        "\n",
        "# Display information about the external data\n",
        "print(\"# External Data: {:,}\".format(len(ext_df)))\n",
        "print(\"# Sample:\")\n",
        "ext_df.head(2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "BGPb5kdapBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ext_df['label'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "KyIEkBZfpBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show distribution of answers using a bar plot\n",
        "plt.figure(figsize=(8, 4))\n",
        "ext_df.name.value_counts().plot.bar(color=[cmap(0.0), cmap(0.65)])\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Answer distribution for External Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "rReijhWMpBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_df = pd.concat([ext_df, df], axis=0).reset_index(drop=True)\n",
        "new_train_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "qdm7ad0BpBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot distribution of real and fake samples\n",
        "plt.figure(figsize=(8, 6))\n",
        "new_train_df['name'].value_counts().plot(kind='bar', color=['blue', 'red'])\n",
        "plt.title('Distribution of Real and Fake Samples')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)  # Rotate x-axis labels if needed\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "yE1csBwxpBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Split**"
      ],
      "metadata": {
        "id": "l4rhcNgmpBq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold  # Import package\n",
        "\n",
        "skf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=CFG.seed)  # Initialize K-Fold\n",
        "\n",
        "new_train_df = new_train_df.reset_index(drop=True)  # Reset dataframe index\n",
        "\n",
        "new_train_df['stratify'] = new_train_df.label.astype(str) + new_train_df.source.astype(str)\n",
        "\n",
        "new_train_df[\"fold\"] = -1  # New 'fold' column\n",
        "\n",
        "# Assign folds using StratifiedKFold\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(new_train_df, new_train_df['stratify'])):\n",
        "    new_train_df.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "# Display label distribution for each fold\n",
        "new_train_df.groupby([\"fold\", \"name\", \"source\"]).size()"
      ],
      "metadata": {
        "trusted": true,
        "id": "m9__T1UspBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Pre-processing**"
      ],
      "metadata": {
        "id": "9EPU2SYmpBq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The preprocessor takes input strings and transforms them into a dictionary (token_ids, padding_mask) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs."
      ],
      "metadata": {
        "id": "6DkbIaNtpBq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
        "    preset=CFG.preset, # Name of the model\n",
        "    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "0vWwKkYApBq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the output shape of the preprocessing layer\n",
        "inp = preprocessor(df.text.iloc[0])  # Process text for the first row\n",
        "\n",
        "# Display the shape of each processed output\n",
        "for k, v in inp.items():\n",
        "    print(k, \":\", v.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hqVvXegnpBq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We'll use the preprocessing_fn function to transform each text option using the dataset.map(preprocessing_fn) method."
      ],
      "metadata": {
        "id": "am_ndgjepBq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_fn(text, label=None):\n",
        "    text = preprocessor(text)  # Preprocess text\n",
        "    return (text, label) if label is not None else text  # Return processed text and label if available"
      ],
      "metadata": {
        "trusted": true,
        "id": "V9A6c1wgpBq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loader**"
      ],
      "metadata": {
        "id": "sq2_Huy3pBq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(texts, labels=None, batch_size=32,\n",
        "                  cache=False, drop_remainder=True,\n",
        "                  repeat=False, shuffle=1024):\n",
        "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
        "    slices = (texts,) if labels is None else (texts, labels)  # Create slices\n",
        "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
        "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
        "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
        "    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n",
        "    opt = tf.data.Options()  # Create dataset options\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
        "        opt.experimental_deterministic = False\n",
        "    ds = ds.with_options(opt)  # Set dataset options\n",
        "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
        "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
        "    return ds  # Return the built dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "1nOZxh9CpBq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetch Train/Valid dataset**"
      ],
      "metadata": {
        "id": "w4FI7tzIpBq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datasets(fold):\n",
        "    train_df = new_train_df[new_train_df.fold!=fold].sample(frac=1)  # Get training fold data\n",
        "\n",
        "    train_texts = train_df.text.tolist()  # Extract training texts\n",
        "    train_labels = train_df.label.tolist()  # Extract training labels\n",
        "\n",
        "    # Build training dataset\n",
        "    train_ds = build_dataset(train_texts, train_labels,\n",
        "                             batch_size=CFG.batch_size*CFG.replicas, cache=CFG.cache,\n",
        "                             shuffle=True, drop_remainder=True, repeat=True)\n",
        "\n",
        "    valid_df = new_train_df[new_train_df.fold==fold].sample(frac=1)  # Get validation fold data\n",
        "    valid_texts = valid_df.text.tolist()  # Extract validation texts\n",
        "    valid_labels = valid_df.label.tolist()  # Extract validation labels\n",
        "\n",
        "    # Build validation dataset\n",
        "    valid_ds = build_dataset(valid_texts, valid_labels,\n",
        "                             batch_size=min(CFG.batch_size*CFG.replicas, len(valid_df)), cache=CFG.cache,\n",
        "                             shuffle=False, drop_remainder=True, repeat=False)\n",
        "\n",
        "    return (train_ds, train_df), (valid_ds, valid_df)  # Return datasets and dataframes"
      ],
      "metadata": {
        "trusted": true,
        "id": "th4byChbpBq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Weights and Biases using WanDB**"
      ],
      "metadata": {
        "id": "FNcrE6kSpBq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb  # Import wandb library for experiment tracking\n",
        "\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient  # Import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()  # Create secrets client instance\n",
        "    api_key = user_secrets.get_secret(\"WANDB\")  # Get API key from Kaggle secrets\n",
        "    wandb.login(key=api_key)  # Login to wandb with the API key\n",
        "    anonymous = None  # Set anonymous mode to None\n",
        "except:\n",
        "    anonymous = 'must'  # Set anonymous mode to 'must'\n",
        "    wandb.login(anonymous=anonymous, relogin=True)  # Login to wandb anonymously and relogin if needed"
      ],
      "metadata": {
        "trusted": true,
        "id": "lV8JZQ5DpBq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Data Logger**"
      ],
      "metadata": {
        "id": "TL2xA43dpBq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializes the W&B run with a config file and W&B run settings.\n",
        "def wandb_init(fold):\n",
        "    config = {k: v for k, v in dict(vars(CFG)).items() if '__' not in k}  # Create config dictionary\n",
        "    config.update({\"fold\": int(fold)})  # Add fold to config\n",
        "    run = wandb.init(project=\"llm-fake-text\",\n",
        "                     name=f\"fold-{fold}|max_seq-{CFG.sequence_length}|model-{CFG.preset}\",\n",
        "                     config=config,\n",
        "                     group=CFG.comment,\n",
        "                     save_code=True)\n",
        "    return run\n",
        "\n",
        "# Log best result for error analysis\n",
        "def log_wandb():\n",
        "    wandb.log({'best_auc': best_auc, 'best_loss': best_loss, 'best_epoch': best_epoch})\n",
        "\n",
        "# Fetch W&B callbacks\n",
        "def get_wb_callbacks(fold):\n",
        "    wb_metr = wandb.keras.WandbMetricsLogger()\n",
        "    return [wb_metr]  # Return WandB callbacks"
      ],
      "metadata": {
        "trusted": true,
        "id": "lf5zx6u_pBq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Learning Rate Scheduler**"
      ],
      "metadata": {
        "id": "J5LYAywHpBq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
        "    lr_start, lr_max, lr_min = 0.6e-6, 0.5e-6 * batch_size, 0.3e-6\n",
        "    lr_ramp_ep, lr_sus_ep, lr_decay = 1, 0, 0.75\n",
        "\n",
        "    def lrfn(epoch):  # Learning rate update function\n",
        "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
        "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
        "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
        "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
        "        elif mode == 'cos':\n",
        "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
        "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
        "        return lr\n",
        "\n",
        "    if plot:  # Plot lr curve if plot is True\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
        "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
        "        plt.title('LR Scheduler')\n",
        "        plt.show()\n",
        "\n",
        "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback"
      ],
      "metadata": {
        "trusted": true,
        "id": "eaGE1m-TpBq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_=get_lr_callback(CFG.batch_size*CFG.replicas, plot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "10gyiTC0pBq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining the Callback function**"
      ],
      "metadata": {
        "id": "wUGoqrD3pBq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_callbacks(fold):\n",
        "    callbacks = []\n",
        "    lr_cb = get_lr_callback(CFG.batch_size*CFG.replicas)  # Get lr callback\n",
        "    ckpt_cb = keras.callbacks.ModelCheckpoint(f'fold{fold}.keras',\n",
        "                                              monitor='val_auc',\n",
        "                                              save_best_only=True,\n",
        "                                              save_weights_only=False,\n",
        "                                              mode='max')  # Get Model checkpoint callback\n",
        "    callbacks.extend([lr_cb, ckpt_cb])  # Add lr and checkpoint callbacks\n",
        "\n",
        "    if CFG.wandb:  # If WandB is enabled\n",
        "        wb_cbs = get_wb_callbacks(fold)  # Get WandB callbacks\n",
        "        callbacks.extend(wb_cbs)\n",
        "\n",
        "    return callbacks  # Return the list of callbacks"
      ],
      "metadata": {
        "trusted": true,
        "id": "o-wBEQ11pBq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining the Model Architecture**"
      ],
      "metadata": {
        "id": "nmwEgTtSpBq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    # Create a DebertaV3Classifier model\n",
        "    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
        "        CFG.preset,\n",
        "        preprocessor=None,\n",
        "        num_classes=1 # one output per one option, for five options total 5 outputs\n",
        "    )\n",
        "    inputs = classifier.input\n",
        "    logits = classifier(inputs)\n",
        "\n",
        "    # Compute final output\n",
        "    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # Compile the model with optimizer, loss, and metrics\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.AdamW(5e-6),\n",
        "        loss=keras.losses.BinaryCrossentropy(label_smoothing=0.02),\n",
        "        metrics=[\n",
        "            keras.metrics.AUC(name=\"auc\"),\n",
        "        ],\n",
        "        jit_compile=True\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "A4L7xxL-pBq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "trusted": true,
        "id": "IcQxgqxcpBq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PbfzxV_5pBq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the Model Structure**"
      ],
      "metadata": {
        "id": "R5NJy6JPpBq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZKS4yY05pBq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "phbup2M7pBq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in CFG.selected_folds:\n",
        "    # Initialize Weights and Biases if enabled\n",
        "    if CFG.wandb:\n",
        "        run = wandb_init(fold)\n",
        "\n",
        "    # Get train and validation datasets\n",
        "    (train_ds, train_df), (valid_ds, valid_df) = get_datasets(fold)\n",
        "\n",
        "    # Get callback functions for training\n",
        "    callbacks = get_callbacks(fold)\n",
        "\n",
        "    # Print training information\n",
        "    print('#' * 50)\n",
        "    print(f'\\tFold: {fold + 1} | Model: {CFG.preset}\\n\\tBatch Size: {CFG.batch_size * CFG.replicas} | Scheduler: {CFG.scheduler}')\n",
        "    print(f'\\tNum Train: {len(train_df)} | Num Valid: {len(valid_df)}')\n",
        "    print('#' * 50)\n",
        "\n",
        "    # Clear TensorFlow session and build the model within the strategy scope\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = build_model()\n",
        "\n",
        "    # Start training the model\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=CFG.epochs,\n",
        "        validation_data=valid_ds,\n",
        "        callbacks=callbacks,\n",
        "        steps_per_epoch=int(len(train_df) / CFG.batch_size / CFG.replicas),\n",
        "    )\n",
        "\n",
        "    # Find the epoch with the best validation accuracy\n",
        "    best_epoch = np.argmax(model.history.history['val_auc'])\n",
        "    best_auc = model.history.history['val_auc'][best_epoch]\n",
        "    best_loss = model.history.history['val_loss'][best_epoch]\n",
        "\n",
        "    # Print and display best results\n",
        "    print(f'\\n{\"=\" * 17} FOLD {fold} RESULTS {\"=\" * 17}')\n",
        "    print(f'>>>> BEST Loss  : {best_loss:.3f}\\n>>>> BEST AUC   : {best_auc:.3f}\\n>>>> BEST Epoch : {best_epoch}')\n",
        "    print('=' * 50)\n",
        "\n",
        "    # Log best result on Weights and Biases (wandb) if enabled\n",
        "    if CFG.wandb:\n",
        "        log_wandb()  # Log results\n",
        "        wandb.run.finish()  # Finish the run\n",
        "#         display(ipd.IFrame(run.url, width=1080, height=720)) # show wandb dashboard\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "Pbm0PEiPpBq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction/Evaluting the Model**"
      ],
      "metadata": {
        "id": "mjqUxBsVpBq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using the trained model on last validation data\n",
        "predictions = model.predict(\n",
        "    valid_ds,\n",
        "    batch_size=min(CFG.batch_size * CFG.replicas * 2, len(valid_df)), # max batch size = valid size\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "GjHtrjgcpBq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format predictions and true answers\n",
        "pred_answers = (predictions > 0.5).astype(int).squeeze()\n",
        "true_answers = valid_df.label.values\n",
        "\n",
        "# Check 5 Predictions\n",
        "print(\"# Predictions\\n\")\n",
        "for i in range(5):\n",
        "    row = valid_df.iloc[i]\n",
        "    text  = row.text\n",
        "    pred_answer = CFG.label2name[pred_answers[i]]\n",
        "    true_answer = CFG.label2name[true_answers[i]]\n",
        "    print(f\"‚ùì Text {i+1}:\\n{text[:100]} .... {text[-100:]}\\n\")\n",
        "    print(f\"‚úÖ True: {true_answer}\\n\")\n",
        "    print(f\"ü§ñ Predicted: {pred_answer}\\n\")\n",
        "    print(\"-\"*90, \"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "1HR6r8gnpBq_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}